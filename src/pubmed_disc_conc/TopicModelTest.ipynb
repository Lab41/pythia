{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Model Test\n",
    "\n",
    "This is a notebook for trying to use topic models for classifying sets of text that are more syntactically similar than topically similar. This notebook attempts to distinguish between discussion and conclusion section of scientific papers.\n",
    "\n",
    "Below we are loading the dataset for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from time import time\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "validDocsDict = dict()\n",
    "fileList = os.listdir(\"BioMedProcessed\")\n",
    "for f in fileList:\n",
    "    validDocsDict.update(pickle.load(open(\"BioMedProcessed/\" + f, \"rb\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are setting some vaiables to be used below and defining a function for printing the top words in a topic for the topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = len(validDocsDict.keys())\n",
    "n_features = 1000\n",
    "n_topics = 2\n",
    "n_top_words = 30\n",
    "\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process data\n",
    "\n",
    "Here we are preprocessing data for use later. This code only grabs the discussion and conclusion sections of the data. We are also creating appropriate labels for the data and spliting the documents up to train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "53034\n",
      "621.583361617\n",
      "1197.39683976\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset...\")\n",
    "t0 = time()\n",
    "documents = []\n",
    "\n",
    "labels = []\n",
    "concLengthTotal = 0\n",
    "discLengthTotal = 0\n",
    "concCount = 0\n",
    "discCount = 0\n",
    "\n",
    "for k in validDocsDict.keys():\n",
    "    if k.startswith(\"conclusion\"):\n",
    "        labels.append(\"conclusion\")\n",
    "        documents.append(validDocsDict[k])\n",
    "        concCount += 1\n",
    "        concLengthTotal += len(validDocsDict[k].split(' '))\n",
    "    elif k.startswith(\"discussion\"):\n",
    "        labels.append(\"discussion\")\n",
    "        documents.append(validDocsDict[k])\n",
    "        discCount += 1\n",
    "        discLengthTotal += len(validDocsDict[k].split(' '))\n",
    "\n",
    "print(len(documents))\n",
    "print(concLengthTotal * 1.0/ concCount)\n",
    "print(discLengthTotal * 1.0/ discCount)\n",
    "\n",
    "train, test, labelsTrain, labelsTest = train_test_split(documents, labels, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are splitting the data up some more to train different models. Discussion and conclusion sections are being put into their own training sets. A TFIDF vectorizer is trained with the whole dataset of conclusion AND discussion sections. The multiple different training sets are then transformed using this vectorizer to get vector encodings of the text normalized to sum to 1 which accounts for differing lengths of conclusion and discussion sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf features for LDA...\n",
      "done in 74.115s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2507: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  VisibleDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "trainSetOne = []\n",
    "trainSetTwo = []\n",
    "\n",
    "for x in range(len(train)):\n",
    "    if labelsTrain[x] == \"conclusion\":\n",
    "        trainSetOne.append(train[x])\n",
    "    else:\n",
    "        trainSetTwo.append(train[x])\n",
    "\n",
    "# Use tf (raw term count) features for LDA.\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = TfidfVectorizer(max_df=0.95, norm = 'l1', min_df=2, max_features=n_features, stop_words='english')\n",
    "t0 = time()\n",
    "tf = tf_vectorizer.fit_transform(train)\n",
    "\n",
    "tfSetOne = tf_vectorizer.transform(trainSetOne)\n",
    "tfSetTwo = tf_vectorizer.transform(trainSetTwo)\n",
    "tfTest = tf_vectorizer.transform(test)\n",
    "test = tfTest\n",
    "train = tf\n",
    "trainSetOne = tfSetOne\n",
    "trainSetTwo = tfSetTwo\n",
    "\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA With Two Topics\n",
    "\n",
    "Define an LDA topic model on the whole data set with two topics. This is trying to see if the topic model can define the difference between the two groups automatically and prints the top words per topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LDA models with tf features, n_samples=157526 and n_features=1000...\n",
      "done in 354.955s.\n",
      "\n",
      "Topics in LDA model:\n",
      "Topic #0:\n",
      "patients health study care 1016 authors risk manuscript treatment clinical data disease use research women patient hiv medical children competing history pre interests analysis publication population design quality pain age\n",
      "Topic #1:\n",
      "background expression gene cells genes cell protein cancer results different human studies activity used species levels model specific proteins present genetic method using dna genome role number data function observed\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting LDA models with tf features, n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=100,\n",
    "                                learning_method='online', learning_offset=50.,\n",
    "                                random_state=0)\n",
    "\n",
    "t0 = time()\n",
    "lda.fit(tf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the unknown data through the topic model and calculate which topic it is more associated with according to the ratios. Calculate how many of each type (conclusion and discussion) go into each topic (1 or 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = lda.transform(test)\n",
    "totalConTop1 = 0\n",
    "totalConTop2 = 0\n",
    "totalDisTop1 = 0\n",
    "totalDisTop2 = 0\n",
    "for x in range(len(results)):\n",
    "    val1 = results[x][0]\n",
    "    val2 = results[x][1]\n",
    "    total = val1 + val2\n",
    "    print(str(labelsTest[x]) + \" \" + str(val1/total) + \" \" + str(val2/total))\n",
    "    if val1 > val2:\n",
    "        if labelsTest[x] == \"conclusion\":\n",
    "            totalConTop1 += 1\n",
    "        else:\n",
    "            totalDisTop1 += 1\n",
    "    else:\n",
    "        if labelsTest[x] == \"conclusion\":\n",
    "            totalConTop2 += 1\n",
    "        else:\n",
    "            totalDisTop2 += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the results from the topic transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Total Conclusion Topic One: \" + str(totalConTop1))\n",
    "print(\"Total Conclusion Topic Two: \" + str(totalConTop2))\n",
    "print(\"Total Discussion Topic One: \" + str(totalDisTop1))\n",
    "print(\"Total Discussion Topic Two: \" + str(totalDisTop2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the parameters for the LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Classifiers\n",
    "\n",
    "Train three basic classifiers to solve the problem. Try Gaussian, Bernoulli and K Nearest Neighbors classifiers and calculate how accurate they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9302413273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifier = GaussianNB()\n",
    "\n",
    "classifier.fit(train.toarray(), labelsTrain)\n",
    "\n",
    "classResults = classifier.predict(test.toarray())\n",
    "\n",
    "numRight = 0\n",
    "\n",
    "for item in range(len(classResults)):\n",
    "    if classResults[item] == labelsTest[item]:\n",
    "        numRight += 1\n",
    "\n",
    "print(str(numRight * 1.0 / len(classResults) * 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.840874811463\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "classifier.fit(train.toarray(), labelsTrain)\n",
    "\n",
    "classResults = classifier.predict(test.toarray())\n",
    "\n",
    "numRight = 0\n",
    "\n",
    "for item in range(len(classResults)):\n",
    "    if classResults[item] == labelsTest[item]:\n",
    "        numRight += 1\n",
    "\n",
    "print(str(numRight * 1.0 / len(classResults) * 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.950791855204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "classifier = BernoulliNB()\n",
    "\n",
    "classifier.fit(train.toarray(), labelsTrain)\n",
    "\n",
    "classResults = classifier.predict(test.toarray())\n",
    "\n",
    "numRight = 0\n",
    "\n",
    "for item in range(len(classResults)):\n",
    "    if classResults[item] == labelsTest[item]:\n",
    "        numRight += 1\n",
    "\n",
    "print(str(numRight * 1.0 / len(classResults) * 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.743212669683\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier()\n",
    "\n",
    "classifier.fit(train, labelsTrain)\n",
    "\n",
    "classResults = classifier.predict(test)\n",
    "numRight = 0\n",
    "\n",
    "for item in range(len(classResults)):\n",
    "    if classResults[item] == labelsTest[item]:\n",
    "        numRight += 1\n",
    "\n",
    "print(str(numRight * 1.0 / len(classResults) * 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "Decision trees work well for binary classification and require little data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.942873303167\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "classifier.fit(train.toarray(), labelsTrain)\n",
    "\n",
    "classResults = classifier.predict(test.toarray())\n",
    "numRight = 0\n",
    "\n",
    "for item in range(len(classResults)):\n",
    "    if classResults[item] == labelsTest[item]:\n",
    "        numRight += 1\n",
    "\n",
    "print(str(numRight * 1.0 / len(classResults) * 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.863122171946\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "classifier = SGDClassifier()\n",
    "\n",
    "classifier.fit(train, labelsTrain)\n",
    "\n",
    "classResults = classifier.predict(test)\n",
    "\n",
    "numRight = 0\n",
    "\n",
    "for item in range(len(classResults)):\n",
    "    if classResults[item] == labelsTest[item]:\n",
    "        numRight += 1\n",
    "\n",
    "print(str(numRight * 1.0 / len(classResults) * 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Topic Models\n",
    "\n",
    "Define two topic models with 20 topics each, one on discussion sections and one on conclusion sections. Then transform both the train and test sets using both topic models to get 40 features for each sample based on the probability distribution for each topic in each LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ldaSet1 = LatentDirichletAllocation(n_topics=20, max_iter=100,\n",
    "                                learning_method='online', learning_offset=50.,\n",
    "                                random_state=0)\n",
    "ldaSet2 = LatentDirichletAllocation(n_topics=20, max_iter=100,\n",
    "                                learning_method='online', learning_offset=50.,\n",
    "                                random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "jama transcriptional p53 income intern healthcare emergency gps questionnaire physicians nursing physician nurses practices prepub perceived students fig rural reason conserved policy reasons noted urban illness s0140 6736 hospitals 1001\n",
      "Topic #1:\n",
      "cancer cell 1016 cells breast expression human background tumor gene 1038 receptor induced manuscript protein authors patients growth factor carcinoma study 1002 biol colorectal apoptosis clin analysis lung gastric competing\n",
      "Topic #2:\n",
      "health 1016 manuscript authors background care study patients data competing interests research publication medical history clinical pre risk analysis hiv disease treatment design med 1097 children women participated cancer patient\n",
      "Topic #3:\n",
      "jama transcriptional p53 income intern healthcare emergency gps questionnaire physicians nursing physician nurses practices prepub perceived students fig rural reason conserved policy reasons noted urban illness s0140 6736 hospitals 1001\n",
      "Topic #4:\n",
      "jama transcriptional p53 income intern healthcare emergency gps questionnaire physicians nursing physician nurses practices prepub perceived students fig rural reason conserved policy reasons noted urban illness s0140 6736 hospitals 1001\n",
      "Topic #5:\n",
      "jama transcriptional p53 income intern healthcare emergency gps questionnaire physicians nursing physician nurses practices prepub perceived students fig rural reason conserved policy reasons noted urban illness s0140 6736 hospitals 1001\n",
      "Topic #6:\n",
      "jama transcriptional p53 income intern healthcare emergency gps questionnaire physicians nursing physician nurses practices prepub perceived students fig rural reason conserved policy reasons noted urban illness s0140 6736 hospitals 1001\n",
      "Topic #7:\n",
      "jama transcriptional p53 income intern healthcare emergency gps questionnaire physicians nursing physician nurses practices prepub perceived students fig rural reason conserved policy reasons noted urban illness s0140 6736 hospitals 1001\n",
      "Topic #8:\n",
      "jama transcriptional p53 income intern healthcare emergency gps questionnaire physicians nursing physician nurses practices prepub perceived students fig rural reason conserved policy reasons noted urban illness s0140 6736 hospitals 1001\n",
      "Topic #9:\n",
      "jama transcriptional p53 income intern healthcare emergency gps questionnaire physicians nursing physician nurses practices prepub perceived students fig rural reason conserved policy reasons noted urban illness s0140 6736 hospitals 1001\n",
      "Topic #10:\n",
      "jama transcriptional p53 income intern healthcare emergency gps questionnaire physicians nursing physician nurses practices prepub perceived students fig rural reason conserved policy reasons noted urban illness s0140 6736 hospitals 1001\n",
      "Topic #11:\n",
      "jama transcriptional p53 income intern healthcare emergency gps questionnaire physicians nursing physician nurses practices prepub perceived students fig rural reason conserved policy reasons noted urban illness s0140 6736 hospitals 1001\n",
      "Topic #12:\n",
      "jama transcriptional p53 income intern healthcare emergency gps questionnaire physicians nursing physician nurses practices prepub perceived students fig rural reason conserved policy reasons noted urban illness s0140 6736 hospitals 1001\n",
      "Topic #13:\n",
      "jama transcriptional p53 income intern healthcare emergency gps questionnaire physicians nursing physician nurses practices prepub perceived students fig rural reason conserved policy reasons noted urban illness s0140 6736 hospitals 1001\n",
      "Topic #14:\n",
      "jama transcriptional p53 income intern healthcare emergency gps questionnaire physicians nursing physician nurses practices prepub perceived students fig rural reason conserved policy reasons noted urban illness s0140 6736 hospitals 1001\n",
      "Topic #15:\n",
      "jama transcriptional p53 income intern healthcare emergency gps questionnaire physicians nursing physician nurses practices prepub perceived students fig rural reason conserved policy reasons noted urban illness s0140 6736 hospitals 1001\n",
      "Topic #16:\n",
      "jama transcriptional p53 income intern healthcare emergency gps questionnaire physicians nursing physician nurses practices prepub perceived students fig rural reason conserved policy reasons noted urban illness s0140 6736 hospitals 1001\n",
      "Topic #17:\n",
      "jama transcriptional p53 income intern healthcare emergency gps questionnaire physicians nursing physician nurses practices prepub perceived students fig rural reason conserved policy reasons noted urban illness s0140 6736 hospitals 1001\n",
      "Topic #18:\n",
      "jama transcriptional p53 income intern healthcare emergency gps questionnaire physicians nursing physician nurses practices prepub perceived students fig rural reason conserved policy reasons noted urban illness s0140 6736 hospitals 1001\n",
      "Topic #19:\n",
      "background genes gene expression genome protein species results data genetic cells study proteins cell analysis method suggest sequence different specific dna evolution novel model using studies new used identified function\n"
     ]
    }
   ],
   "source": [
    "ldaSet1.fit(trainSetOne)\n",
    "print_top_words(ldaSet1, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "kinase mice apoptosis mitochondrial allele amino loci nursing chromosome signaling promoter p53 gps snp snps mrna transcriptional conserved income emergency microarray students questionnaire physician jama genome nurses intern school linkage\n",
      "Topic #1:\n",
      "patients study treatment et al patient reported disease cases studies renal surgery clinical cancer therapy risk bone case levels group blood associated pain dose rate present diagnosis results serum tumor\n",
      "Topic #2:\n",
      "kinase mice apoptosis mitochondrial allele amino loci nursing chromosome signaling promoter p53 gps snp snps mrna transcriptional conserved income emergency microarray students questionnaire physician jama genome nurses intern school linkage\n",
      "Topic #3:\n",
      "kinase mice apoptosis mitochondrial allele amino loci nursing chromosome signaling promoter p53 gps snp snps mrna transcriptional conserved income emergency microarray students questionnaire physician jama genome nurses intern school linkage\n",
      "Topic #4:\n",
      "kinase mice apoptosis mitochondrial allele amino loci nursing chromosome signaling promoter p53 gps snp snps mrna transcriptional conserved income emergency microarray students questionnaire physician jama genome nurses intern school linkage\n",
      "Topic #5:\n",
      "kinase mice apoptosis mitochondrial allele amino loci nursing chromosome signaling promoter p53 gps snp snps mrna transcriptional conserved income emergency microarray students questionnaire physician jama genome nurses intern school linkage\n",
      "Topic #6:\n",
      "kinase mice apoptosis mitochondrial allele amino loci nursing chromosome signaling promoter p53 gps snp snps mrna transcriptional conserved income emergency microarray students questionnaire physician jama genome nurses intern school linkage\n",
      "Topic #7:\n",
      "kinase mice apoptosis mitochondrial allele amino loci nursing chromosome signaling promoter p53 gps snp snps mrna transcriptional conserved income emergency microarray students questionnaire physician jama genome nurses intern school linkage\n",
      "Topic #8:\n",
      "kinase mice apoptosis mitochondrial allele amino loci nursing chromosome signaling promoter p53 gps snp snps mrna transcriptional conserved income emergency microarray students questionnaire physician jama genome nurses intern school linkage\n",
      "Topic #9:\n",
      "study patients health care women studies risk use data reported children patient population results age hiv time treatment participants students higher prevalence information medical group findings high research clinical used\n",
      "Topic #10:\n",
      "kinase mice apoptosis mitochondrial allele amino loci nursing chromosome signaling promoter p53 gps snp snps mrna transcriptional conserved income emergency microarray students questionnaire physician jama genome nurses intern school linkage\n",
      "Topic #11:\n",
      "kinase mice apoptosis mitochondrial allele amino loci nursing chromosome signaling promoter p53 gps snp snps mrna transcriptional conserved income emergency microarray students questionnaire physician jama genome nurses intern school linkage\n",
      "Topic #12:\n",
      "kinase mice apoptosis mitochondrial allele amino loci nursing chromosome signaling promoter p53 gps snp snps mrna transcriptional conserved income emergency microarray students questionnaire physician jama genome nurses intern school linkage\n",
      "Topic #13:\n",
      "kinase mice apoptosis mitochondrial allele amino loci nursing chromosome signaling promoter p53 gps snp snps mrna transcriptional conserved income emergency microarray students questionnaire physician jama genome nurses intern school linkage\n",
      "Topic #14:\n",
      "kinase mice apoptosis mitochondrial allele amino loci nursing chromosome signaling promoter p53 gps snp snps mrna transcriptional conserved income emergency microarray students questionnaire physician jama genome nurses intern school linkage\n",
      "Topic #15:\n",
      "kinase mice apoptosis mitochondrial allele amino loci nursing chromosome signaling promoter p53 gps snp snps mrna transcriptional conserved income emergency microarray students questionnaire physician jama genome nurses intern school linkage\n",
      "Topic #16:\n",
      "cells expression genes gene cell protein proteins study species cancer different data dna figure activity results sequence observed binding studies shown levels genome used analysis sequences human present et al\n",
      "Topic #17:\n",
      "kinase mice apoptosis mitochondrial allele amino loci nursing chromosome signaling promoter p53 gps snp snps mrna transcriptional conserved income emergency microarray students questionnaire physician jama genome nurses intern school linkage\n",
      "Topic #18:\n",
      "kinase mice apoptosis mitochondrial allele amino loci nursing chromosome signaling promoter p53 gps snp snps mrna transcriptional conserved income emergency microarray students questionnaire physician jama genome nurses intern school linkage\n",
      "Topic #19:\n",
      "kinase mice apoptosis mitochondrial allele amino loci nursing chromosome signaling promoter p53 gps snp snps mrna transcriptional conserved income emergency microarray students questionnaire physician jama genome nurses intern school linkage\n"
     ]
    }
   ],
   "source": [
    "ldaSet2.fit(trainSetTwo)\n",
    "print_top_words(ldaSet2, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results1 = ldaSet1.transform(train)\n",
    "results2 = ldaSet2.transform(train)\n",
    "\n",
    "resultsTest1 = ldaSet1.transform(test)\n",
    "resultsTest2 = ldaSet2.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = np.hstack((results1, results2))\n",
    "resultsTest = np.hstack((resultsTest1, resultsTest2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define two classifiers using the transformed train and test sets from the topic models. Print out the accuracy of each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59125188537\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifier = GaussianNB()\n",
    "\n",
    "classifier.fit(results, labelsTrain)\n",
    "\n",
    "classResults = classifier.predict(resultsTest)\n",
    "\n",
    "numRight = 0\n",
    "\n",
    "for item in range(len(classResults)):\n",
    "    if classResults[item] == labelsTest[item]:\n",
    "        numRight += 1\n",
    "\n",
    "print(str(numRight * 1.0 / len(classResults) * 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.786010558069\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier()\n",
    "\n",
    "classifier.fit(results, labelsTrain)\n",
    "\n",
    "classResults = classifier.predict(resultsTest)\n",
    "\n",
    "numRight = 0\n",
    "\n",
    "for item in range(len(classResults)):\n",
    "    if classResults[item] == labelsTest[item]:\n",
    "        numRight += 1\n",
    "\n",
    "print(str(numRight * 1.0 / len(classResults) * 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.590497737557\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "classifier.fit(results, labelsTrain)\n",
    "\n",
    "classResults = classifier.predict(resultsTest)\n",
    "\n",
    "numRight = 0\n",
    "\n",
    "for item in range(len(classResults)):\n",
    "    if classResults[item] == labelsTest[item]:\n",
    "        numRight += 1\n",
    "\n",
    "print(str(numRight * 1.0 / len(classResults) * 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.588989441931\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "classifier = SGDClassifier()\n",
    "\n",
    "classifier.fit(results, labelsTrain)\n",
    "\n",
    "classResults = classifier.predict(resultsTest)\n",
    "\n",
    "numRight = 0\n",
    "\n",
    "for item in range(len(classResults)):\n",
    "    if classResults[item] == labelsTest[item]:\n",
    "        numRight += 1\n",
    "\n",
    "print(str(numRight * 1.0 / len(classResults) * 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the results of each sample of 40 features so they sum to 1. Then train two more classifiers using the data and print out the accuracy of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in range(len(results)):\n",
    "    total = 0\n",
    "    for y in range(len(results[x])):\n",
    "        total += results[x][y]\n",
    "    for y in range(len(results[x])):\n",
    "        results[x][y] = results[x][y]/total\n",
    "        \n",
    "for x in range(len(resultsTest)):\n",
    "    total = 0\n",
    "    for y in range(len(resultsTest[x])):\n",
    "        total += resultsTest[x][y]\n",
    "    for y in range(len(resultsTest[x])):\n",
    "        resultsTest[x][y] = resultsTest[x][y]/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.496606334842\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifier = GaussianNB()\n",
    "\n",
    "classifier.fit(results, labelsTrain)\n",
    "\n",
    "classResults = classifier.predict(resultsTest)\n",
    "\n",
    "numRight = 0\n",
    "\n",
    "for item in range(len(classResults)):\n",
    "    if classResults[item] == labelsTest[item]:\n",
    "        numRight += 1\n",
    "\n",
    "print(str(numRight * 1.0 / len(classResults) * 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.786010558069\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier()\n",
    "\n",
    "classifier.fit(results, labelsTrain)\n",
    "\n",
    "classResults = classifier.predict(resultsTest)\n",
    "\n",
    "numRight = 0\n",
    "\n",
    "for item in range(len(classResults)):\n",
    "    if classResults[item] == labelsTest[item]:\n",
    "        numRight += 1\n",
    "\n",
    "print(str(numRight * 1.0 / len(classResults) * 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.591063348416\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "classifier.fit(results, labelsTrain)\n",
    "\n",
    "classResults = classifier.predict(resultsTest)\n",
    "\n",
    "numRight = 0\n",
    "\n",
    "for item in range(len(classResults)):\n",
    "    if classResults[item] == labelsTest[item]:\n",
    "        numRight += 1\n",
    "\n",
    "print(str(numRight * 1.0 / len(classResults) * 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.588989441931\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "classifier = SGDClassifier()\n",
    "\n",
    "classifier.fit(results, labelsTrain)\n",
    "\n",
    "classResults = classifier.predict(resultsTest)\n",
    "\n",
    "numRight = 0\n",
    "\n",
    "for item in range(len(classResults)):\n",
    "    if classResults[item] == labelsTest[item]:\n",
    "        numRight += 1\n",
    "\n",
    "print(str(numRight * 1.0 / len(classResults) * 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
