{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import subprocess\n",
    "import json\n",
    "from lxml import etree\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gen_url(section):\n",
    "    return 'https://ia800500.us.archive.org/22/items/stackexchange/' + section + '.stackexchange.com.7z'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \n",
    "    #add titles of sections to download\n",
    "    sections = {'3dprinting', 'academia', 'android', 'anime', 'apple', 'arabic', 'arduino', 'sports'}\n",
    "\n",
    "    stack_exchange_data = list()\n",
    "    for section in sections:\n",
    "        stack_exchange_data.append((section, gen_url(section)))\n",
    "    \n",
    "    return stack_exchange_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_directory(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup():\n",
    "    \n",
    "    #makes folder for all stack exchange data\n",
    "    directory = 'stack_exchange_data'\n",
    "    make_directory(directory)\n",
    "    \n",
    "    #makes folder for zip files\n",
    "    zip_directory = os.path.join(directory, 'zip_files')\n",
    "    make_directory(zip_directory)\n",
    "    \n",
    "    #makes folder for corpus\n",
    "    corpus_directory = os.path.join(directory, 'corpus')\n",
    "    make_directory(corpus_directory)\n",
    "    \n",
    "    return directory, zip_directory, corpus_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def section_setup(section, directory, zip_directory, corpus_directory):\n",
    "    \n",
    "    #makes folder for section\n",
    "    section_directory = os.path.join(directory, section + \"_files\")\n",
    "    make_directory(section_directory)\n",
    "\n",
    "    #info for section files\n",
    "    file_name = section + \"_stackexchange.7z\"\n",
    "    full_file_name = os.path.join(zip_directory, file_name)\n",
    "    \n",
    "    corpus_section_directory = os.path.join(corpus_directory, section)\n",
    "    make_directory(corpus_section_directory)\n",
    "    \n",
    "    return full_file_name, section_directory, corpus_section_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load(url, file_name, folder):\n",
    "\n",
    "    #downloads file from url\n",
    "    testfile = urllib.URLopener()\n",
    "    testfile.retrieve(url, file_name)\n",
    "\n",
    "    #un-zips file and puts contents in folder\n",
    "    cmd = r'\"/usr/local/bin/7z\" x ' + file_name + ' -o' + folder\n",
    "    subprocess.call(cmd, shell = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_links(folder):\n",
    "    tree = etree.parse(folder +\"/PostLinks.xml\")\n",
    "    return tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gen_clusters(links):\n",
    "    unused_id = 1\n",
    "    \n",
    "    related_link = '1'\n",
    "    duplicate_link = '3'\n",
    "    \n",
    "    clusters = dict()\n",
    "    related = dict()\n",
    "    duplicates = dict()\n",
    "    unique_posts = set()\n",
    "    \n",
    "    for l in links:\n",
    "        post_id = l.attrib['PostId']\n",
    "        related_id = l.attrib['RelatedPostId']\n",
    "        new_ids = {post_id, related_id}\n",
    "        unique_posts = unique_posts.union(new_ids)\n",
    "        post_cluster_id = None\n",
    "        related_cluster_id = None\n",
    "        for c in clusters:\n",
    "            ids = clusters[c]\n",
    "            if post_id in ids:\n",
    "                post_cluster_id = c\n",
    "            elif related_id in ids:\n",
    "                related_cluster_id = c\n",
    "        if not (post_cluster_id or related_cluster_id):\n",
    "            cluster_id = unused_id\n",
    "            clusters[cluster_id] = set()\n",
    "            duplicates[cluster_id] = set()\n",
    "            related[cluster_id] = set()\n",
    "            unused_id+=1\n",
    "        elif not related_cluster_id:\n",
    "            cluster_id = post_cluster_id\n",
    "        elif not post_cluster_id:\n",
    "            cluster_id = related_cluster_id\n",
    "        else: #both ids appeared in clusters\n",
    "            post_cluster = clusters[post_cluster_id]\n",
    "            related_cluster = clusters[related_cluster_id]\n",
    "            clusters[post_cluster_id] = post_cluster.union(related_cluster)\n",
    "            del clusters[related_cluster_id]\n",
    "            cluster_id = post_cluster_id\n",
    "        clusters[cluster_id] = clusters[cluster_id].union(new_ids)\n",
    "        if l.attrib['LinkTypeId'] == related_link:\n",
    "            related[cluster_id] = related[cluster_id].union(new_ids)\n",
    "        else: # l.attrib['LinkTypeId'] == duplicate:\n",
    "            if not l.attrib['LinkTypeId'] == duplicate_link:\n",
    "                print l.attrib['LinkTypeId']\n",
    "            duplicates[cluster_id] = clusters[cluster_id].union(new_ids)\n",
    "    return clusters, related, duplicates, unique_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_posts(folder):\n",
    "    tree = etree.parse(folder +\"/Posts.xml\")\n",
    "    return tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_up(raw_text):\n",
    "    return BeautifulSoup(raw_text, \"lxml\").get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gen_corpus(posts, unique_posts):  \n",
    "    corpus = dict()\n",
    "\n",
    "    for p in posts:\n",
    "        id = p.attrib['Id']\n",
    "        if id in unique_posts:\n",
    "            try:\n",
    "                corpus[id] = clean_up(p.attrib['Title']) + ' ' + clean_up(p.attrib['Body'])  \n",
    "            except:\n",
    "                pass\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_json_files(clusters, related, duplicates, corpus, corpus_directory):\n",
    "    next_cluster_id = 0\n",
    "    for cluster_id in clusters:\n",
    "        time_stamp = 0\n",
    "        file_name = str(next_cluster_id) + '.json'\n",
    "        full_file_name = os.path.join(corpus_directory, file_name)\n",
    "        with open(full_file_name, 'w') as outfile:\n",
    "            if duplicates.has_key(cluster_id):\n",
    "                novel = True\n",
    "                for duplicate in duplicates[cluster_id]:\n",
    "                    if corpus.has_key(duplicate):\n",
    "                        d = dict()\n",
    "                        d['cluster_id'] = next_cluster_id\n",
    "                        d['post_id'] = duplicate\n",
    "                        d['order'] = time_stamp\n",
    "                        d['body_text'] = corpus[duplicate]\n",
    "                        d['novelty'] = novel\n",
    "                        json.dump(d, outfile)\n",
    "                        outfile.write('\\n')\n",
    "                        novel = False\n",
    "                        time_stamp+=1\n",
    "            for related_post in related[cluster_id]:\n",
    "                if not corpus.has_key(related_post):\n",
    "                    if corpus.has_key(related_post):\n",
    "                        r = dict()\n",
    "                        r['cluster_id'] = next_cluster_id\n",
    "                        r['post_id'] = related_post\n",
    "                        r['order'] = time_stamp\n",
    "                        r['body_text'] = corpus[related_post]\n",
    "                        r['novelty'] = True\n",
    "                        json.dump(r, outfile)\n",
    "                        outfile.write('\\n')\n",
    "                        time_stamp+=1\n",
    "        next_cluster_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main(argv):\n",
    "    \n",
    "    #gets urls based on sections and creates basic directories\n",
    "    stack_exchange_data = get_data()\n",
    "    directory, zip_directory, corpus_directory = setup()\n",
    "        \n",
    "    for (section, url) in stack_exchange_data:\n",
    "\n",
    "        #creates directorys for section\n",
    "        file_name, folder_name, corpus_section_directory = section_setup(section, directory, zip_directory, corpus_directory)\n",
    "        \n",
    "        #downloads and unzips section file\n",
    "        load(url, file_name, folder_name)\n",
    "\n",
    "        #gets the links from the links file\n",
    "        links = get_links(folder_name)\n",
    "\n",
    "        #creates the clusters\n",
    "        clusters, related, duplicates, unique_posts = gen_clusters(links)\n",
    "\n",
    "        #gets the posts from the posts file\n",
    "        posts = get_posts(folder_name)\n",
    "\n",
    "        #creates the corpus with the body text for each id in the clusters\n",
    "        corpus = gen_corpus(posts, unique_posts)\n",
    "        \n",
    "        #writes the information to json files\n",
    "        write_json_files(clusters, related, duplicates, corpus, corpus_section_directory)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
