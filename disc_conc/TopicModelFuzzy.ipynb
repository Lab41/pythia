{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Model Fuzzy\n",
    "\n",
    "This is a notebook for trying to use topic models for classifying sets of text that are more syntactically similar than topically similar. This notebook attempts to distinguish between discussion and conclusion section of scientific papers. This notebook also augments the data with random sentences from the introduction section.\n",
    "\n",
    "Below we are loading the dataset for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from time import time\n",
    "import os\n",
    "from random import randint\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "validDocsDict = dict()\n",
    "fileList = os.listdir(\"BioMedProcessed\")\n",
    "for f in fileList:\n",
    "    validDocsDict.update(pickle.load(open(\"BioMedProcessed/\" + f, \"rb\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are setting some vaiables to be used below and defining a function for printing the top words in a topic for the topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = len(validDocsDict.keys())\n",
    "n_features = 1000\n",
    "n_topics = 2\n",
    "n_top_words = 30\n",
    "lengthOfIntroToAdd = 500\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process data\n",
    "\n",
    "Here we are preprocessing data for use later. This code grabs the introduction, discussion and conclusion sections of the data. We are also creating appropriate labels for the data and spliting the documents up to train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Loading dataset...\")\n",
    "t0 = time()\n",
    "documents = []\n",
    "introductionSections = []\n",
    "\n",
    "labels = []\n",
    "concLengthTotal = 0\n",
    "discLengthTotal = 0\n",
    "concCount = 0\n",
    "discCount = 0\n",
    "introCount = 0\n",
    "\n",
    "for k in validDocsDict.keys():\n",
    "    if k.startswith(\"conclusion\"):\n",
    "        labels.append(\"conclusion\")\n",
    "        documents.append(validDocsDict[k])\n",
    "        concCount += 1\n",
    "        concLengthTotal += len(validDocsDict[k].split(' '))\n",
    "    elif k.startswith(\"discussion\"):\n",
    "        labels.append(\"discussion\")\n",
    "        documents.append(validDocsDict[k])\n",
    "        discCount += 1\n",
    "        discLengthTotal += len(validDocsDict[k].split(' '))\n",
    "    elif k.startswith(\"introduction\") and len(validDocsDict[k]) > 5000:\n",
    "        introCount += 1\n",
    "        introductionSections.append(validDocsDict[k])\n",
    "\n",
    "print(len(documents))\n",
    "print(concLengthTotal * 1.0/ concCount)\n",
    "print(discLengthTotal * 1.0/ discCount)\n",
    "print(introCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add some random introduction sections to the discussion and conclusion sections to add some noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for item in range(len(documents)):\n",
    "    if labels[item] == \"conclusion\":\n",
    "        intro = introductionSections[randint(0, len(introductionSections) - 1)].split(\" \")\n",
    "        randNum = randint(0, len(intro) - lengthOfIntroToAdd)\n",
    "        introWords = intro[randNum:randNum + lengthOfIntroToAdd]\n",
    "        documents[item] = documents[item] + \" \".join(introWords)\n",
    "\n",
    "train, test, labelsTrain, labelsTest = train_test_split(documents, labels, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are splitting the data up some more to train different models. Discussion and conclusion sections are being put into their own training sets. A TFIDF vectorizer is trained with the whole dataset of conclusion AND discussion sections. The multiple different training sets are then transformed using this vectorizer to get vector encodings of the text normalized to sum to 1 which accounts for differing lengths of conclusion and discussion sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainSetOne = []\n",
    "trainSetTwo = []\n",
    "\n",
    "for x in range(len(train)):\n",
    "    if labelsTrain[x] == \"conclusion\":\n",
    "        trainSetOne.append(train[x])\n",
    "    else:\n",
    "        trainSetTwo.append(train[x])\n",
    "\n",
    "# Use tf (raw term count) features for LDA.\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = TfidfVectorizer(max_df=0.95, norm = 'l1', min_df=2, max_features=n_features, stop_words='english')\n",
    "t0 = time()\n",
    "tf = tf_vectorizer.fit_transform(train)\n",
    "\n",
    "tfSetOne = tf_vectorizer.transform(trainSetOne)\n",
    "tfSetTwo = tf_vectorizer.transform(trainSetTwo)\n",
    "tfTest = tf_vectorizer.transform(test)\n",
    "test = tfTest\n",
    "train = tf\n",
    "trainSetOne = tfSetOne\n",
    "trainSetTwo = tfSetTwo\n",
    "\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA With Two Topics\n",
    "\n",
    "Define an LDA topic model on the whole data set with two topics. This is trying to see if the topic model can define the difference between the two groups automatically and prints the top words per topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Fitting LDA models with tf features, n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=100,\n",
    "                                learning_method='online', learning_offset=50.,\n",
    "                                random_state=0)\n",
    "\n",
    "t0 = time()\n",
    "lda.fit(tf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the unknown data through the topic model and calculate which topic it is more associated with according to the ratios. Calculate how many of each type (conclusion and discussion) go into each topic (1 or 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = lda.transform(test)\n",
    "totalConTop1 = 0\n",
    "totalConTop2 = 0\n",
    "totalDisTop1 = 0\n",
    "totalDisTop2 = 0\n",
    "for x in range(len(results)):\n",
    "    val1 = results[x][0]\n",
    "    val2 = results[x][1]\n",
    "    total = val1 + val2\n",
    "    print(str(labelsTest[x]) + \" \" + str(val1/total) + \" \" + str(val2/total))\n",
    "    if val1 > val2:\n",
    "        if labelsTest[x] == \"conclusion\":\n",
    "            totalConTop1 += 1\n",
    "        else:\n",
    "            totalDisTop1 += 1\n",
    "    else:\n",
    "        if labelsTest[x] == \"conclusion\":\n",
    "            totalConTop2 += 1\n",
    "        else:\n",
    "            totalDisTop2 += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the results from the topic transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Total Conclusion Topic One: \" + str(totalConTop1))\n",
    "print(\"Total Conclusion Topic Two: \" + str(totalConTop2))\n",
    "print(\"Total Discussion Topic One: \" + str(totalDisTop1))\n",
    "print(\"Total Discussion Topic Two: \" + str(totalDisTop2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the parameters for the LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Classifiers\n",
    "\n",
    "Train three basic classifiers to solve the problem. Try Gaussian, Bernoulli and K Nearest Neighbors classifiers and calculate how accurate they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifier = GaussianNB()\n",
    "\n",
    "classifier.fit(train.toarray(), labelsTrain)\n",
    "\n",
    "classResults = classifier.predict(test.toarray())\n",
    "\n",
    "numRight = 0\n",
    "\n",
    "for item in range(len(classResults)):\n",
    "    if classResults[item] == labelsTest[item]:\n",
    "        numRight += 1\n",
    "\n",
    "print(str(numRight * 1.0 / len(classResults) * 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "classifier = BernoulliNB()\n",
    "\n",
    "classifier.fit(train.toarray(), labelsTrain)\n",
    "\n",
    "classResults = classifier.predict(test.toarray())\n",
    "\n",
    "numRight = 0\n",
    "\n",
    "for item in range(len(classResults)):\n",
    "    if classResults[item] == labelsTest[item]:\n",
    "        numRight += 1\n",
    "\n",
    "print(str(numRight * 1.0 / len(classResults) * 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier()\n",
    "\n",
    "classifier.fit(train, labelsTrain)\n",
    "\n",
    "classResults = classifier.predict(test)\n",
    "numRight = 0\n",
    "\n",
    "for item in range(len(classResults)):\n",
    "    if classResults[item] == labelsTest[item]:\n",
    "        numRight += 1\n",
    "\n",
    "print(str(numRight * 1.0 / len(classResults) * 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Topic Models\n",
    "\n",
    "Define two topic models with 20 topics each, one on discussion sections and one on conclusion sections. Then transform both the train and test sets using both topic models to get 40 features for each sample based on the probability distribution for each topic in each LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldaSet1 = LatentDirichletAllocation(n_topics=20, max_iter=100,\n",
    "                                learning_method='online', learning_offset=50.,\n",
    "                                random_state=0)\n",
    "ldaSet2 = LatentDirichletAllocation(n_topics=20, max_iter=100,\n",
    "                                learning_method='online', learning_offset=50.,\n",
    "                                random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ldaSet1.fit(trainSetOne)\n",
    "print_top_words(ldaSet1, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ldaSet2.fit(trainSetTwo)\n",
    "print_top_words(ldaSet2, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results1 = ldaSet1.transform(train)\n",
    "results2 = ldaSet2.transform(train)\n",
    "\n",
    "resultsTest1 = ldaSet1.transform(test)\n",
    "resultsTest2 = ldaSet2.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = np.hstack((results1, results2))\n",
    "resultsTest = np.hstack((resultsTest1, resultsTest2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define two classifiers using the transformed train and test sets from the topic models. Print out the accuracy of each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifier = GaussianNB()\n",
    "\n",
    "classifier.fit(results, labelsTrain)\n",
    "\n",
    "classResults = classifier.predict(resultsTest)\n",
    "\n",
    "numRight = 0\n",
    "\n",
    "for item in range(len(classResults)):\n",
    "    if classResults[item] == labelsTest[item]:\n",
    "        numRight += 1\n",
    "\n",
    "print(str(numRight * 1.0 / len(classResults) * 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier()\n",
    "\n",
    "classifier.fit(results, labelsTrain)\n",
    "\n",
    "classResults = classifier.predict(resultsTest)\n",
    "\n",
    "numRight = 0\n",
    "\n",
    "for item in range(len(classResults)):\n",
    "    if classResults[item] == labelsTest[item]:\n",
    "        numRight += 1\n",
    "\n",
    "print(str(numRight * 1.0 / len(classResults) * 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the results of each sample of 40 features so they sum to 1. Then train two more classifiers using the data and print out the accuracy of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in range(len(results)):\n",
    "    total = 0\n",
    "    for y in range(len(results[x])):\n",
    "        total += results[x][y]\n",
    "    for y in range(len(results[x])):\n",
    "        results[x][y] = results[x][y]/total\n",
    "        \n",
    "for x in range(len(resultsTest)):\n",
    "    total = 0\n",
    "    for y in range(len(resultsTest[x])):\n",
    "        total += resultsTest[x][y]\n",
    "    for y in range(len(resultsTest[x])):\n",
    "        resultsTest[x][y] = resultsTest[x][y]/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifier = GaussianNB()\n",
    "\n",
    "classifier.fit(results, labelsTrain)\n",
    "\n",
    "classResults = classifier.predict(resultsTest)\n",
    "\n",
    "numRight = 0\n",
    "\n",
    "for item in range(len(classResults)):\n",
    "    if classResults[item] == labelsTest[item]:\n",
    "        numRight += 1\n",
    "\n",
    "print(str(numRight * 1.0 / len(classResults) * 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier()\n",
    "\n",
    "classifier.fit(results, labelsTrain)\n",
    "\n",
    "classResults = classifier.predict(resultsTest)\n",
    "\n",
    "numRight = 0\n",
    "\n",
    "for item in range(len(classResults)):\n",
    "    if classResults[item] == labelsTest[item]:\n",
    "        numRight += 1\n",
    "\n",
    "print(str(numRight * 1.0 / len(classResults) * 1.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
