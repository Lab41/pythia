{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Model Two Datasets Memory Efficient Fuzzy\n",
    "\n",
    "This is a notebook for trying to use topic models for classifying sets of text that are more syntactically similar than topically similar. This notebook attempts to distinguish between discussion and conclusion section of scientific papers. This modifies the sections with random words from the introduction sections. It also reads the second dataset in a more memory efficient way.\n",
    "\n",
    "Below we are loading the two datasets for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from time import time\n",
    "from random import randint\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "validDocsDict = dict()\n",
    "fileList = os.listdir(\"BioMedProcessed\")\n",
    "for f in fileList:\n",
    "    validDocsDict.update(pickle.load(open(\"BioMedProcessed/\" + f, \"rb\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are setting some vaiables to be used below and defining a function for printing the top words in a topic for the topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = len(validDocsDict.keys())\n",
    "n_features = 10000\n",
    "n_topics = 2\n",
    "n_top_words = 30\n",
    "lengthOfIntroToAdd = 700\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data\n",
    "\n",
    "Here we are preprocessing data for use later. This code only grabs the discussion and conclusion sections of the data. We are also creating appropriate labels for the data and spliting the documents up to train and test sets. We do this for both sets of data and then for a combined set of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "53034\n",
      "621.583361617\n",
      "1197.39683976\n",
      "1213\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset...\")\n",
    "t0 = time()\n",
    "documents = []\n",
    "introductionSections = []\n",
    "\n",
    "labels = []\n",
    "concLengthTotal = 0\n",
    "discLengthTotal = 0\n",
    "concCount = 0\n",
    "discCount = 0\n",
    "introCount = 0\n",
    "\n",
    "for k in validDocsDict.keys():\n",
    "    if k.startswith(\"conclusion\"):\n",
    "        labels.append(\"conclusion\")\n",
    "        documents.append(validDocsDict[k])\n",
    "        concCount += 1\n",
    "        concLengthTotal += len(validDocsDict[k].split(' '))\n",
    "    elif k.startswith(\"discussion\"):\n",
    "        labels.append(\"discussion\")\n",
    "        documents.append(validDocsDict[k])\n",
    "        discCount += 1\n",
    "        discLengthTotal += len(validDocsDict[k].split(' '))\n",
    "    elif k.startswith(\"introduction\") and len(validDocsDict[k]) > 10000:\n",
    "        introCount += 1\n",
    "        introductionSections.append(validDocsDict[k])\n",
    "\n",
    "print(len(documents))\n",
    "print(concLengthTotal * 1.0/ concCount)\n",
    "print(discLengthTotal * 1.0/ discCount)\n",
    "print(introCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are reading in the files of the second dataset and only keeping the important sections. We are reading the files in one file at a time to be more memory efficient. Also, note that because the PubMed dataset is much larger, we are only reading in a third of the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27688\n",
      "3392\n"
     ]
    }
   ],
   "source": [
    "validDocs2 = []\n",
    "labels2 = []\n",
    "fileList = os.listdir(\"PubMedProcessed\")\n",
    "for f in fileList[0:len(fileList)/3]:\n",
    "    tempDict = pickle.load(open(\"PubMedProcessed/\" + f, \"rb\"))\n",
    "    for item in tempDict.keys():\n",
    "        if item.startswith(\"conclusion\"):\n",
    "            labels2.append(\"conclusion\")\n",
    "            validDocs2.append(tempDict[item])\n",
    "        elif item.startswith(\"discussion\"):\n",
    "            labels2.append(\"discussion\")\n",
    "            validDocs2.append(tempDict[item])\n",
    "        elif item.startswith(\"introduction\") and len(tempDict[item]) > 10000:\n",
    "            introCount += 1\n",
    "            introductionSections.append(tempDict[item])\n",
    "\n",
    "print(len(validDocs2))\n",
    "print(introCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are adding random introduction words to the conclusion and discussion sections to replicate noise. Because the sections are tfidf vectorized, it is not important where in the section they are inserted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for item in range(len(documents)):\n",
    "    intro = introductionSections[randint(0, len(introductionSections) - 1)].split(\" \")\n",
    "    randNum = randint(0, len(intro) - lengthOfIntroToAdd)\n",
    "    introWords = intro[randNum:randNum + lengthOfIntroToAdd]\n",
    "    documents[item] = documents[item] + \" \".join(introWords)\n",
    "\n",
    "for item in range(len(validDocs2)):\n",
    "    intro = introductionSections[randint(0, len(introductionSections) - 1)].split(\" \")\n",
    "    randNum = randint(0, len(intro) - lengthOfIntroToAdd)\n",
    "    introWords = intro[randNum:randNum + lengthOfIntroToAdd]\n",
    "    validDocs2[item] = validDocs2[item] + \" \".join(introWords)\n",
    "    \n",
    "train, test, labelsTrain, labelsTest = train_test_split(documents, labels, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are splitting the data up some more to train different models. Discussion and conclusion sections are being put into their own training sets. A TFIDF vectorizer is trained with the whole dataset of conclusion AND discussion sections from both data sets. The multiple different training sets are then transformed using this vectorizer to get vector encodings of the text normalized to sum to 1 which accounts for differing lengths of conclusion and discussion sections and between data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf features for LDA...\n",
      "done in 132.906s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2507: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  VisibleDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Use tf (raw term count) features for LDA.\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = TfidfVectorizer(max_df=0.95, norm = 'l1', min_df=2, max_features=n_features, stop_words='english')\n",
    "t0 = time()\n",
    "tf_vectorizer.fit(train)\n",
    "tf = tf_vectorizer.transform(train)\n",
    "\n",
    "tfTest = tf_vectorizer.transform(test)\n",
    "test = tfTest\n",
    "train = tf\n",
    "\n",
    "pubTest = tf_vectorizer.transform(validDocs2)\n",
    "\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Classifiers Between Two Datasets\n",
    "\n",
    "Train and test two Bernoulli classifiers (one where dataset 1 is trained and one where dataset 2 is trained) and print out the results of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.886629586825\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "classifier = BernoulliNB()\n",
    "\n",
    "classifier.fit(train.toarray(), labelsTrain)\n",
    "\n",
    "classResults = classifier.predict(pubTest.toarray())\n",
    "\n",
    "numRight = 0\n",
    "\n",
    "for item in range(len(classResults)):\n",
    "    if classResults[item] == labels2[item]:\n",
    "        numRight += 1\n",
    "\n",
    "print(str(numRight * 1.0 / len(classResults) * 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.934045673581\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "classifier = BernoulliNB()\n",
    "\n",
    "classifier.fit(pubTest.toarray(), labels2)\n",
    "\n",
    "classResults = classifier.predict(train.toarray())\n",
    "\n",
    "numRight = 0\n",
    "\n",
    "for item in range(len(classResults)):\n",
    "    if classResults[item] == labelsTrain[item]:\n",
    "        numRight += 1\n",
    "\n",
    "print(str(numRight * 1.0 / len(classResults) * 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probas = classifier.predict_log_proba(train.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TotalRight = 0\n",
    "TotalWrong = 0\n",
    "numRight = 0\n",
    "numWrong = 0\n",
    "RightNumbers = []\n",
    "WrongNumbers = []\n",
    "for item in range(len(classResults)):\n",
    "    if classResults[item] == labelsTrain[item]:\n",
    "        TotalRight += probas[item][0] + probas[item][1]\n",
    "        numRight += 1\n",
    "        RightNumbers.append(probas[item][0] + probas[item][1])\n",
    "    else:\n",
    "        TotalWrong += probas[item][0] + probas[item][1]\n",
    "        numWrong += 1\n",
    "        WrongNumbers.append(probas[item][0] + probas[item][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-62.4955817234\n",
      "-21.1156799732\n"
     ]
    }
   ],
   "source": [
    "print(str(TotalRight * 1.0 / numRight))\n",
    "print(str(TotalWrong * 1.0 / numWrong))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
