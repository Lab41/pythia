{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open a single json and look at it\n",
    "\n",
    "Bring in the data as a dictionary and then it is quite easy to read in as a Pandas to play around with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('stack_exchange_data/corpus/apple/0.json') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'body_text': u'External Disk to use with iTunes in a AirPort Extreme I have a external disk that I use now to have my iTunes collection, I want to connect the same disk to the AirPort Extreme so I dont have to use a USB port in my Notebook. \\nDoes anyone have a reccomendation?\\n',\n",
       "  u'cluster_id': 0,\n",
       "  u'novelty': True,\n",
       "  u'order': 0,\n",
       "  u'post_id': u'391'},\n",
       " {u'body_text': u'External Disk to use with TimeMachine in a AirPort Extreme Any one know any external disk that I can use to do this?\\n',\n",
       "  u'cluster_id': 0,\n",
       "  u'order': 1,\n",
       "  u'post_id': u'390'}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd_data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_text</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>novelty</th>\n",
       "      <th>order</th>\n",
       "      <th>post_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>External Disk to use with iTunes in a AirPort ...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>External Disk to use with TimeMachine in a Air...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           body_text  cluster_id novelty  \\\n",
       "0  External Disk to use with iTunes in a AirPort ...           0    True   \n",
       "1  External Disk to use with TimeMachine in a Air...           0     NaN   \n",
       "\n",
       "   order post_id  \n",
       "0      0     391  \n",
       "1      1     390  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#bring in all the json files from a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_all = []\n",
    "for filename in os.listdir('stack_exchange_data/corpus/apple/'):\n",
    "    if filename.endswith('.json'):\n",
    "        with open('stack_exchange_data/corpus/apple/' + filename) as f:\n",
    "            for line in f:\n",
    "                data_all.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = 'stack_exchange_data/corpus/apple/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put this all together to demo the code that is in utils/load_json_to_pandas.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_all = []\n",
    "if file_path.endswith('.json'):\n",
    "    with open(file_path) as f:\n",
    "            for line in f:\n",
    "                data_all.append(json.loads(line))\n",
    "else:\n",
    "    try:\n",
    "        for filename in os.listdir(file_path):\n",
    "            if filename.endswith('.json'):\n",
    "                with open(file_path + filename) as f:\n",
    "                    for line in f:\n",
    "                        data_all.append(json.loads(line))\n",
    "    except:\n",
    "        print(\"Only *.json files or folders can be processed.  Error processing: \" + file_path)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5110"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd_data_all = pd.DataFrame(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_text</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>novelty</th>\n",
       "      <th>order</th>\n",
       "      <th>post_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>External Disk to use with iTunes in a AirPort ...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>External Disk to use with TimeMachine in a Air...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Merge two accounts on iTunes? I just noticed t...</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is it possible to merge two iTunes Store accou...</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Swap key €-&gt;$ permanently I have a Macbook Air...</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>8787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           body_text  cluster_id novelty  \\\n",
       "0  External Disk to use with iTunes in a AirPort ...           0    True   \n",
       "1  External Disk to use with TimeMachine in a Air...           0   False   \n",
       "2  Merge two accounts on iTunes? I just noticed t...          10    True   \n",
       "3  Is it possible to merge two iTunes Store accou...          10   False   \n",
       "4  Swap key €->$ permanently I have a Macbook Air...         100    True   \n",
       "\n",
       "   order post_id  \n",
       "0      0     391  \n",
       "1      1     390  \n",
       "2      0    1594  \n",
       "3      1    1460  \n",
       "4      0    8787  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_data_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A handy webpage to see how to query data in Pandas is at: http://pandas.pydata.org/pandas-docs/stable/comparison_with_sql.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster_id\n",
       "0        2\n",
       "4        5\n",
       "7        2\n",
       "8        3\n",
       "9       11\n",
       "10       2\n",
       "11       1\n",
       "12       1\n",
       "14       1\n",
       "17       2\n",
       "18       2\n",
       "21       1\n",
       "22       2\n",
       "23       6\n",
       "24       4\n",
       "27       2\n",
       "29       2\n",
       "32       5\n",
       "38      15\n",
       "41       3\n",
       "43       3\n",
       "44       2\n",
       "46       7\n",
       "48       3\n",
       "50       4\n",
       "51       8\n",
       "57       4\n",
       "59       5\n",
       "62       3\n",
       "67      11\n",
       "        ..\n",
       "4357     4\n",
       "4371     2\n",
       "4373     2\n",
       "4375     1\n",
       "4378     3\n",
       "4379     2\n",
       "4386     4\n",
       "4392     2\n",
       "4393     3\n",
       "4394     2\n",
       "4398     4\n",
       "4415     3\n",
       "4416    11\n",
       "4417     2\n",
       "4421     2\n",
       "4423     2\n",
       "4426     3\n",
       "4429     2\n",
       "4430     2\n",
       "4438     2\n",
       "4439     2\n",
       "4453     3\n",
       "4457     2\n",
       "4458     2\n",
       "4468     2\n",
       "4470     2\n",
       "4471     2\n",
       "4474     2\n",
       "4478     4\n",
       "4494     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look to see how many documents are in each cluster\n",
    "pd_data_all.groupby(\"cluster_id\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1350"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so how many clusters are there (those with non-zero which this current dataset has)?\n",
    "len(pd_data_all.groupby(\"cluster_id\").size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We are going to try to bring in the data into Spark.\n",
    "#If you aren't running Spark or have PySpark this part will not work...\n",
    "from pyspark import SparkContext, SparkConf \n",
    "from pyspark.sql import SQLContext \n",
    "\n",
    "try:\n",
    "    sc = SparkContext()\n",
    "except:\n",
    "    sc = SparkContext._active_spark_context\n",
    "\n",
    "sqlCtx = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data1 = sqlCtx.read.json(\"stack_exchange_data/corpus/apple/921.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(body_text=u\"Upgrade to higher memory or faster processor on MacBook Air I'm zeroing on buying the 2012 MacBook Air. My usage of the machine will be mostly for development work (MySQL, Eclipse, Xcode, Android, etc.). I will also be running Windows 7 with SQL Server in a virtual box or by using Boot Camp. My question is which upgrade will result in the most bang for the buck: more RAM or a faster processor? Does putting higher memory/processor make the machine run hotter?\\n\", cluster_id=921, novelty=True, order=0, post_id=u'55074')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(body_text=u\"Upgrade to higher memory or faster processor on MacBook Air I'm zeroing on buying the 2012 MacBook Air. My usage of the machine will be mostly for development work (MySQL, Eclipse, Xcode, Android, etc.). I will also be running Windows 7 with SQL Server in a virtual box or by using Boot Camp. My question is which upgrade will result in the most bang for the buck: more RAM or a faster processor? Does putting higher memory/processor make the machine run hotter?\\n\", cluster_id=921, novelty=True, order=0, post_id=u'55074')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.registerTempTable(\"stack\")\n",
    "sqlCtx.sql(\"select * from stack where order=0\").take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- body_text: string (nullable = true)\n",
      " |-- cluster_id: long (nullable = true)\n",
      " |-- novelty: boolean (nullable = true)\n",
      " |-- order: long (nullable = true)\n",
      " |-- post_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#very similar things that I did above can be done in Spark"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
